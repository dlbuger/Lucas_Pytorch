{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torch.optim as topti\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for creating the neural network.\n",
    "class NetworkLstm(tnn.Module):\n",
    "    \"\"\"\n",
    "    Implement an LSTM-based network that accepts batched 50-d\n",
    "    vectorized inputs, with the following structure:\n",
    "    LSTM(hidden dim = 100) -> Linear(64) -> ReLu-> Linear(1)\n",
    "    Assume batch-first ordering.\n",
    "    Output should be 1d tensor of shape [batch_size].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NetworkLstm, self).__init__()\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        Create and initialise weights and biases for the layers.\n",
    "        \"\"\"\n",
    "        self.lstm = torch.nn.LSTM(50,100,batch_first=True)\n",
    "        self.dense1 = torch.nn.Linear(100,64)\n",
    "        self.A1 = torch.nn.ReLU()\n",
    "        self.dense2 = torch.nn.Linear(64,1)\n",
    "\n",
    "\n",
    "    def forward(self, input, length):\n",
    "        \"\"\"\n",
    "        DO NOT MODIFY FUNCTION SIGNATURE\n",
    "        TODO:\n",
    "        Create the forward pass through the network.\n",
    "        \"\"\"\n",
    "        o,(h_n,h_c) = self.lstm(input)\n",
    "        x = h_n\n",
    "        x = self.dense1(x)\n",
    "        x = self.A1(x)\n",
    "        x = self.dense2(x).view(-1)\n",
    "\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetworkCnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \" + str(device))\n",
    "    # Load the training dataset, and create a data loader to generate a batch.\n",
    "    textField = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "    labelField = data.Field(sequential=False)\n",
    "\n",
    "    from imdb_dataloader import IMDB\n",
    "    train, dev = IMDB.splits(textField, labelField, train=\"train\", validation=\"dev\")\n",
    "\n",
    "    textField.build_vocab(train, dev, vectors=GloVe(name=\"6B\", dim=50))\n",
    "    labelField.build_vocab(train, dev)\n",
    "\n",
    "    trainLoader, testLoader = data.BucketIterator.splits((train, dev), shuffle=True, batch_size=64,\n",
    "                                                         sort_key=lambda x: len(x.text), sort_within_batch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NetworkCnn().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetworkCnn(\n",
      "  (conv1): Conv1d(50, 50, kernel_size=(8,), stride=(1,), padding=(5,))\n",
      "  (relu): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(50, 50, kernel_size=(8,), stride=(1,), padding=(5,))\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(50, 50, kernel_size=(8,), stride=(1,), padding=(5,))\n",
      "  (dense): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "for i, batch in enumerate(trainLoader):\n",
    "    # Get a batch and potentially send it to GPU memory.\n",
    "    inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "        device), batch.label.type(torch.FloatTensor).to(device)\n",
    "    o = net(inputs,length)\n",
    "    shapes.append(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([40]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for creating the neural network.\n",
    "class NetworkCnn(tnn.Module):\n",
    "    \"\"\"\n",
    "    Implement a Convolutional Neural Network.\n",
    "    All conv layers should be of the form:\n",
    "    conv1d(channels=50, kernel size=8, padding=5)\n",
    "\n",
    "    Conv -> ReLu -> maxpool(size=4) -> Conv -> ReLu -> maxpool(size=4) ->\n",
    "    Conv -> ReLu -> maxpool over time (global pooling) -> Linear(1)\n",
    "\n",
    "    The max pool over time operation refers to taking the\n",
    "    maximum val from the entire output channel. See Kim et. al. 2014:\n",
    "    https://www.aclweb.org/anthology/D14-1181/\n",
    "    Assume batch-first ordering.\n",
    "    Output should be 1d tensor of shape [batch_size].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        Create and initialise weights and biases for the layers.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(50, 50, 8, padding=5,)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool1 = torch.nn.MaxPool1d(4)\n",
    "        self.conv2 = torch.nn.Conv1d(50, 50, 8, padding=5)\n",
    "        # ReLu\n",
    "        self.pool2 = torch.nn.MaxPool1d(4)\n",
    "        self.conv3 = torch.nn.Conv1d(50, 50, 8, padding=5)\n",
    "        # ReLu\n",
    "        self.global_pool = torch.nn.functional.max_pool1d\n",
    "        self.dense = torch.nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, input, length): \n",
    "        \"\"\"\n",
    "        DO NOT MODIFY FUNCTION SIGNATURE\n",
    "        TODO:\n",
    "        Create the forward pass through the network.\n",
    "        \"\"\"\n",
    "        x = self.conv1(input.permute(0,2,1))\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.global_pool(x,kernel_size=x.shape[2])\n",
    "        x = self.dense(x.view(-1,50))\n",
    "        return torch.sigmoid(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFunc():\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    Return a loss function appropriate for the above networks that\n",
    "    will add a sigmoid to the output and calculate the binary\n",
    "    cross-entropy.\n",
    "    \"\"\"\n",
    "    return torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures(outputs, labels):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    Return (in the following order): the number of true positive\n",
    "    classifications, true negatives, false positives and false\n",
    "    negatives from the given batch outputs and provided labels.\n",
    "    \n",
    "    https://webcms3.cse.unsw.edu.au/COMP9444/19T3/resources/36531 第12页\n",
    "    https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative\n",
    "    \n",
    "    outputs and labels are torch tensors.\n",
    "    \"\"\"\n",
    "    length = labels.shape[0]\n",
    "    tp_batch = tn_batch = fp_batch = fn_batch = 0\n",
    "    #outputs = outputs.view(-1).to(torch.device('cpu')).numpy()\n",
    "    outputs = (outputs.view(-1) >= 0.5).to(int)\n",
    "\n",
    "    for i in range(length):\n",
    "        if outputs[i] - labels[i] == 1:\n",
    "            fp_batch += 1\n",
    "        if outputs[i] - labels[i] == -1:\n",
    "            fn_batch += 1\n",
    "        if outputs[i] - labels[i] == 0:\n",
    "            if outputs[i] == 1:\n",
    "                tp_batch += 1\n",
    "            else:\n",
    "                tn_batch += 1\n",
    "    return tp_batch, tn_batch, fp_batch, fn_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Epoch:  1, Batch:   32, Loss: 0.697\n",
      "Epoch:  1, Batch:   64, Loss: 0.693\n",
      "Epoch:  1, Batch:   96, Loss: 0.670\n",
      "Epoch:  1, Batch:  128, Loss: 0.614\n",
      "Epoch:  1, Batch:  160, Loss: 0.594\n",
      "Epoch:  1, Batch:  192, Loss: 0.533\n",
      "Epoch:  1, Batch:  224, Loss: 0.551\n",
      "Epoch:  1, Batch:  256, Loss: 0.526\n",
      "Epoch:  1, Batch:  288, Loss: 0.499\n",
      "Epoch:  1, Batch:  320, Loss: 0.506\n",
      "Epoch:  1, Batch:  352, Loss: 0.515\n",
      "Epoch:  1, Batch:  384, Loss: 0.475\n",
      "Epoch:  2, Batch:   32, Loss: 0.460\n",
      "Epoch:  2, Batch:   64, Loss: 0.468\n",
      "Epoch:  2, Batch:   96, Loss: 0.475\n",
      "Epoch:  2, Batch:  128, Loss: 0.461\n",
      "Epoch:  2, Batch:  160, Loss: 0.437\n",
      "Epoch:  2, Batch:  192, Loss: 0.437\n",
      "Epoch:  2, Batch:  224, Loss: 0.430\n",
      "Epoch:  2, Batch:  256, Loss: 0.419\n",
      "Epoch:  2, Batch:  288, Loss: 0.409\n",
      "Epoch:  2, Batch:  320, Loss: 0.382\n",
      "Epoch:  2, Batch:  352, Loss: 0.395\n",
      "Epoch:  2, Batch:  384, Loss: 0.415\n",
      "Epoch:  3, Batch:   32, Loss: 0.378\n",
      "Epoch:  3, Batch:   64, Loss: 0.379\n",
      "Epoch:  3, Batch:   96, Loss: 0.374\n",
      "Epoch:  3, Batch:  128, Loss: 0.375\n",
      "Epoch:  3, Batch:  160, Loss: 0.372\n",
      "Epoch:  3, Batch:  192, Loss: 0.384\n",
      "Epoch:  3, Batch:  224, Loss: 0.373\n",
      "Epoch:  3, Batch:  256, Loss: 0.365\n",
      "Epoch:  3, Batch:  288, Loss: 0.370\n",
      "Epoch:  3, Batch:  320, Loss: 0.414\n",
      "Epoch:  3, Batch:  352, Loss: 0.386\n",
      "Epoch:  3, Batch:  384, Loss: 0.359\n",
      "Epoch:  4, Batch:   32, Loss: 0.346\n",
      "Epoch:  4, Batch:   64, Loss: 0.307\n",
      "Epoch:  4, Batch:   96, Loss: 0.319\n",
      "Epoch:  4, Batch:  128, Loss: 0.335\n",
      "Epoch:  4, Batch:  160, Loss: 0.349\n",
      "Epoch:  4, Batch:  192, Loss: 0.362\n",
      "Epoch:  4, Batch:  224, Loss: 0.323\n",
      "Epoch:  4, Batch:  256, Loss: 0.322\n",
      "Epoch:  4, Batch:  288, Loss: 0.339\n",
      "Epoch:  4, Batch:  320, Loss: 0.356\n",
      "Epoch:  4, Batch:  352, Loss: 0.327\n",
      "Epoch:  4, Batch:  384, Loss: 0.339\n",
      "Epoch:  5, Batch:   32, Loss: 0.266\n",
      "Epoch:  5, Batch:   64, Loss: 0.297\n",
      "Epoch:  5, Batch:   96, Loss: 0.280\n",
      "Epoch:  5, Batch:  128, Loss: 0.294\n",
      "Epoch:  5, Batch:  160, Loss: 0.292\n",
      "Epoch:  5, Batch:  192, Loss: 0.337\n",
      "Epoch:  5, Batch:  224, Loss: 0.316\n",
      "Epoch:  5, Batch:  256, Loss: 0.281\n",
      "Epoch:  5, Batch:  288, Loss: 0.313\n",
      "Epoch:  5, Batch:  320, Loss: 0.299\n",
      "Epoch:  5, Batch:  352, Loss: 0.292\n",
      "Epoch:  5, Batch:  384, Loss: 0.305\n",
      "Classification accuracy: 83.59%\n",
      "Matthews Correlation Coefficient: 0.67\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    # Use a GPU if available, as it should be faster.\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \" + str(device))\n",
    "    # Load the training dataset, and create a data loader to generate a batch.\n",
    "    textField = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "    labelField = data.Field(sequential=False)\n",
    "\n",
    "    from imdb_dataloader import IMDB\n",
    "    train, dev = IMDB.splits(textField, labelField, train=\"train\", validation=\"dev\")\n",
    "\n",
    "    textField.build_vocab(train, dev, vectors=GloVe(name=\"6B\", dim=50))\n",
    "    labelField.build_vocab(train, dev)\n",
    "\n",
    "    trainLoader, testLoader = data.BucketIterator.splits((train, dev), shuffle=True, batch_size=64,\n",
    "                                                         sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "\n",
    "    # Create an instance of the network in memory (potentially GPU memory). Can change to NetworkCnn during development.\n",
    "    net = NetworkCnn().to(device)\n",
    "\n",
    "    criterion = lossFunc()\n",
    "    optimiser = topti.Adam(net.parameters(), lr=0.001)  # Minimise the loss using the Adam algorithm.\n",
    "\n",
    "    for epoch in range(5):\n",
    "        running_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(trainLoader):\n",
    "            # Get a batch and potentially send it to GPU memory.\n",
    "            inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "            labels -= 1\n",
    "\n",
    "            # PyTorch calculates gradients by accumulating contributions to them (useful for\n",
    "            # RNNs).  Hence we must manually set them to zero before calculating them.\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Forward pass through the network.\n",
    "            output = net(inputs, length)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # Calculate gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Minimise the loss according to the gradient.\n",
    "            optimiser.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 32 == 31:\n",
    "                print(\"Epoch: %2d, Batch: %4d, Loss: %.3f\" % (epoch + 1, i + 1, running_loss / 32))\n",
    "                running_loss = 0\n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n",
    "\n",
    "    # Evaluate network on the test dataset.  We aren't calculating gradients, so disable autograd to speed up\n",
    "    # computations and reduce memory usage.\n",
    "    with torch.no_grad():\n",
    "        for batch in testLoader:\n",
    "            # Get a batch and potentially send it to GPU memory.\n",
    "            inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            labels -= 1\n",
    "\n",
    "            outputs = net(inputs, length)\n",
    "            tp_batch, tn_batch, fp_batch, fn_batch = measures(outputs, labels)\n",
    "            true_pos += tp_batch\n",
    "            true_neg += tn_batch\n",
    "            false_pos += fp_batch\n",
    "            false_neg += fn_batch\n",
    "            \n",
    "    accuracy = 100 * (true_pos + true_neg) / len(dev)\n",
    "    matthews = MCC(true_pos, true_neg, false_pos, false_neg)\n",
    "\n",
    "    print(\"Classification accuracy: %.2f%%\\n\"\n",
    "          \"Matthews Correlation Coefficient: %.2f\" % (accuracy, matthews))\n",
    "\n",
    "\n",
    "# Matthews Correlation Coefficient calculation.\n",
    "def MCC(tp, tn, fp, fn):\n",
    "    numerator = tp * tn - fp * fn\n",
    "    denominator = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        return np.divide(numerator, denominator)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
