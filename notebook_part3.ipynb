{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as topti\n",
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe\n",
    "from imdb_dataloader import IMDB\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "textField = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "labelField = data.Field(sequential=False)\n",
    "\n",
    "from imdb_dataloader import IMDB\n",
    "train, dev = IMDB.splits(textField, labelField, train=\"train\", validation=\"dev\")\n",
    "\n",
    "textField.build_vocab(train, dev, vectors=GloVe(name=\"6B\", dim=50))\n",
    "labelField.build_vocab(train, dev)\n",
    "\n",
    "trainLoader, testLoader = data.BucketIterator.splits((train, dev), shuffle=True, batch_size=64,\n",
    "                                                     sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tnn.LSTM(50, 100, batch_first=True).to(device)\n",
    "dense1 = torch.nn.Linear(100,64).to(device)\n",
    "dense2 = torch.nn.Linear(64,1).to(device)\n",
    "\n",
    "def fit(inputs):\n",
    "    o = lstm(inputs)\n",
    "    return o\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[torch.Size([64, 176, 100]), tensor(176, device='cuda:0')],\n",
       " [torch.Size([64, 156, 100]), tensor(156, device='cuda:0')],\n",
       " [torch.Size([64, 278, 100]), tensor(278, device='cuda:0')],\n",
       " [torch.Size([64, 42, 100]), tensor(42, device='cuda:0')],\n",
       " [torch.Size([64, 101, 100]), tensor(101, device='cuda:0')],\n",
       " [torch.Size([64, 335, 100]), tensor(335, device='cuda:0')],\n",
       " [torch.Size([64, 182, 100]), tensor(182, device='cuda:0')],\n",
       " [torch.Size([64, 165, 100]), tensor(165, device='cuda:0')],\n",
       " [torch.Size([64, 204, 100]), tensor(204, device='cuda:0')],\n",
       " [torch.Size([64, 168, 100]), tensor(168, device='cuda:0')],\n",
       " [torch.Size([64, 264, 100]), tensor(264, device='cuda:0')],\n",
       " [torch.Size([64, 253, 100]), tensor(253, device='cuda:0')],\n",
       " [torch.Size([64, 185, 100]), tensor(185, device='cuda:0')],\n",
       " [torch.Size([64, 645, 100]), tensor(645, device='cuda:0')],\n",
       " [torch.Size([64, 146, 100]), tensor(146, device='cuda:0')],\n",
       " [torch.Size([64, 928, 100]), tensor(928, device='cuda:0')],\n",
       " [torch.Size([64, 216, 100]), tensor(216, device='cuda:0')],\n",
       " [torch.Size([64, 780, 100]), tensor(780, device='cuda:0')],\n",
       " [torch.Size([64, 91, 100]), tensor(91, device='cuda:0')],\n",
       " [torch.Size([64, 96, 100]), tensor(96, device='cuda:0')],\n",
       " [torch.Size([64, 54, 100]), tensor(54, device='cuda:0')],\n",
       " [torch.Size([64, 70, 100]), tensor(70, device='cuda:0')],\n",
       " [torch.Size([64, 178, 100]), tensor(178, device='cuda:0')],\n",
       " [torch.Size([64, 126, 100]), tensor(126, device='cuda:0')],\n",
       " [torch.Size([64, 1839, 100]), tensor(1839, device='cuda:0')],\n",
       " [torch.Size([64, 139, 100]), tensor(139, device='cuda:0')],\n",
       " [torch.Size([64, 487, 100]), tensor(487, device='cuda:0')],\n",
       " [torch.Size([64, 60, 100]), tensor(60, device='cuda:0')],\n",
       " [torch.Size([64, 569, 100]), tensor(569, device='cuda:0')],\n",
       " [torch.Size([64, 413, 100]), tensor(413, device='cuda:0')],\n",
       " [torch.Size([64, 221, 100]), tensor(221, device='cuda:0')],\n",
       " [torch.Size([64, 173, 100]), tensor(173, device='cuda:0')],\n",
       " [torch.Size([64, 201, 100]), tensor(201, device='cuda:0')],\n",
       " [torch.Size([64, 701, 100]), tensor(701, device='cuda:0')],\n",
       " [torch.Size([64, 271, 100]), tensor(271, device='cuda:0')],\n",
       " [torch.Size([64, 131, 100]), tensor(131, device='cuda:0')],\n",
       " [torch.Size([64, 510, 100]), tensor(510, device='cuda:0')],\n",
       " [torch.Size([64, 605, 100]), tensor(605, device='cuda:0')],\n",
       " [torch.Size([64, 452, 100]), tensor(452, device='cuda:0')],\n",
       " [torch.Size([64, 356, 100]), tensor(356, device='cuda:0')],\n",
       " [torch.Size([64, 243, 100]), tensor(243, device='cuda:0')],\n",
       " [torch.Size([64, 108, 100]), tensor(108, device='cuda:0')],\n",
       " [torch.Size([64, 190, 100]), tensor(190, device='cuda:0')],\n",
       " [torch.Size([64, 80, 100]), tensor(80, device='cuda:0')],\n",
       " [torch.Size([64, 112, 100]), tensor(112, device='cuda:0')],\n",
       " [torch.Size([64, 49, 100]), tensor(49, device='cuda:0')],\n",
       " [torch.Size([64, 308, 100]), tensor(308, device='cuda:0')],\n",
       " [torch.Size([64, 116, 100]), tensor(116, device='cuda:0')],\n",
       " [torch.Size([64, 129, 100]), tensor(129, device='cuda:0')],\n",
       " [torch.Size([64, 287, 100]), tensor(287, device='cuda:0')],\n",
       " [torch.Size([64, 259, 100]), tensor(259, device='cuda:0')],\n",
       " [torch.Size([64, 170, 100]), tensor(170, device='cuda:0')],\n",
       " [torch.Size([64, 382, 100]), tensor(382, device='cuda:0')],\n",
       " [torch.Size([64, 226, 100]), tensor(226, device='cuda:0')],\n",
       " [torch.Size([64, 316, 100]), tensor(316, device='cuda:0')],\n",
       " [torch.Size([64, 142, 100]), tensor(142, device='cuda:0')],\n",
       " [torch.Size([64, 148, 100]), tensor(148, device='cuda:0')],\n",
       " [torch.Size([64, 133, 100]), tensor(133, device='cuda:0')],\n",
       " [torch.Size([64, 158, 100]), tensor(158, device='cuda:0')],\n",
       " [torch.Size([64, 468, 100]), tensor(468, device='cuda:0')],\n",
       " [torch.Size([64, 247, 100]), tensor(247, device='cuda:0')],\n",
       " [torch.Size([64, 137, 100]), tensor(137, device='cuda:0')],\n",
       " [torch.Size([64, 197, 100]), tensor(197, device='cuda:0')],\n",
       " [torch.Size([64, 76, 100]), tensor(76, device='cuda:0')],\n",
       " [torch.Size([64, 188, 100]), tensor(188, device='cuda:0')],\n",
       " [torch.Size([64, 105, 100]), tensor(105, device='cuda:0')],\n",
       " [torch.Size([64, 122, 100]), tensor(122, device='cuda:0')],\n",
       " [torch.Size([64, 326, 100]), tensor(326, device='cuda:0')],\n",
       " [torch.Size([64, 114, 100]), tensor(114, device='cuda:0')],\n",
       " [torch.Size([64, 144, 100]), tensor(144, device='cuda:0')],\n",
       " [torch.Size([64, 66, 100]), tensor(66, device='cuda:0')],\n",
       " [torch.Size([64, 125, 100]), tensor(125, device='cuda:0')],\n",
       " [torch.Size([64, 230, 100]), tensor(230, device='cuda:0')],\n",
       " [torch.Size([64, 293, 100]), tensor(293, device='cuda:0')],\n",
       " [torch.Size([64, 118, 100]), tensor(118, device='cuda:0')],\n",
       " [torch.Size([64, 300, 100]), tensor(300, device='cuda:0')],\n",
       " [torch.Size([64, 141, 100]), tensor(141, device='cuda:0')],\n",
       " [torch.Size([64, 135, 100]), tensor(135, device='cuda:0')],\n",
       " [torch.Size([64, 430, 100]), tensor(430, device='cuda:0')],\n",
       " [torch.Size([64, 121, 100]), tensor(121, device='cuda:0')],\n",
       " [torch.Size([64, 128, 100]), tensor(128, device='cuda:0')],\n",
       " [torch.Size([64, 152, 100]), tensor(152, device='cuda:0')],\n",
       " [torch.Size([64, 238, 100]), tensor(238, device='cuda:0')],\n",
       " [torch.Size([64, 212, 100]), tensor(212, device='cuda:0')],\n",
       " [torch.Size([64, 154, 100]), tensor(154, device='cuda:0')],\n",
       " [torch.Size([64, 541, 100]), tensor(541, device='cuda:0')],\n",
       " [torch.Size([64, 150, 100]), tensor(150, device='cuda:0')],\n",
       " [torch.Size([64, 208, 100]), tensor(208, device='cuda:0')],\n",
       " [torch.Size([64, 160, 100]), tensor(160, device='cuda:0')],\n",
       " [torch.Size([64, 399, 100]), tensor(399, device='cuda:0')],\n",
       " [torch.Size([64, 120, 100]), tensor(120, device='cuda:0')],\n",
       " [torch.Size([64, 345, 100]), tensor(345, device='cuda:0')],\n",
       " [torch.Size([64, 367, 100]), tensor(367, device='cuda:0')],\n",
       " [torch.Size([64, 194, 100]), tensor(194, device='cuda:0')],\n",
       " [torch.Size([64, 234, 100]), tensor(234, device='cuda:0')],\n",
       " [torch.Size([64, 134, 100]), tensor(134, device='cuda:0')],\n",
       " [torch.Size([64, 163, 100]), tensor(163, device='cuda:0')],\n",
       " [torch.Size([64, 85, 100]), tensor(85, device='cuda:0')],\n",
       " [torch.Size([64, 110, 100]), tensor(110, device='cuda:0')],\n",
       " [torch.Size([64, 124, 100]), tensor(124, device='cuda:0')],\n",
       " [torch.Size([64, 127, 100]), tensor(127, device='cuda:0')],\n",
       " [torch.Size([64, 49, 100]), tensor(49, device='cuda:0')],\n",
       " [torch.Size([64, 477, 100]), tensor(477, device='cuda:0')],\n",
       " [torch.Size([64, 90, 100]), tensor(90, device='cuda:0')],\n",
       " [torch.Size([64, 295, 100]), tensor(295, device='cuda:0')],\n",
       " [torch.Size([64, 360, 100]), tensor(360, device='cuda:0')],\n",
       " [torch.Size([64, 108, 100]), tensor(108, device='cuda:0')],\n",
       " [torch.Size([64, 201, 100]), tensor(201, device='cuda:0')],\n",
       " [torch.Size([64, 244, 100]), tensor(244, device='cuda:0')],\n",
       " [torch.Size([64, 144, 100]), tensor(144, device='cuda:0')],\n",
       " [torch.Size([64, 249, 100]), tensor(249, device='cuda:0')],\n",
       " [torch.Size([64, 331, 100]), tensor(331, device='cuda:0')],\n",
       " [torch.Size([64, 84, 100]), tensor(84, device='cuda:0')],\n",
       " [torch.Size([64, 174, 100]), tensor(174, device='cuda:0')],\n",
       " [torch.Size([64, 235, 100]), tensor(235, device='cuda:0')],\n",
       " [torch.Size([64, 160, 100]), tensor(160, device='cuda:0')],\n",
       " [torch.Size([64, 140, 100]), tensor(140, device='cuda:0')],\n",
       " [torch.Size([64, 172, 100]), tensor(172, device='cuda:0')],\n",
       " [torch.Size([64, 153, 100]), tensor(153, device='cuda:0')],\n",
       " [torch.Size([64, 217, 100]), tensor(217, device='cuda:0')],\n",
       " [torch.Size([64, 205, 100]), tensor(205, device='cuda:0')],\n",
       " [torch.Size([64, 130, 100]), tensor(130, device='cuda:0')],\n",
       " [torch.Size([64, 260, 100]), tensor(260, device='cuda:0')],\n",
       " [torch.Size([64, 503, 100]), tensor(503, device='cuda:0')],\n",
       " [torch.Size([64, 533, 100]), tensor(533, device='cuda:0')],\n",
       " [torch.Size([64, 133, 100]), tensor(133, device='cuda:0')],\n",
       " [torch.Size([64, 120, 100]), tensor(120, device='cuda:0')],\n",
       " [torch.Size([64, 170, 100]), tensor(170, device='cuda:0')],\n",
       " [torch.Size([64, 569, 100]), tensor(569, device='cuda:0')],\n",
       " [torch.Size([64, 117, 100]), tensor(117, device='cuda:0')],\n",
       " [torch.Size([64, 209, 100]), tensor(209, device='cuda:0')],\n",
       " [torch.Size([64, 136, 100]), tensor(136, device='cuda:0')],\n",
       " [torch.Size([64, 155, 100]), tensor(155, device='cuda:0')],\n",
       " [torch.Size([64, 131, 100]), tensor(131, device='cuda:0')],\n",
       " [torch.Size([64, 385, 100]), tensor(385, device='cuda:0')],\n",
       " [torch.Size([64, 180, 100]), tensor(180, device='cuda:0')],\n",
       " [torch.Size([64, 188, 100]), tensor(188, device='cuda:0')],\n",
       " [torch.Size([64, 350, 100]), tensor(350, device='cuda:0')],\n",
       " [torch.Size([64, 372, 100]), tensor(372, device='cuda:0')],\n",
       " [torch.Size([64, 58, 100]), tensor(58, device='cuda:0')],\n",
       " [torch.Size([64, 191, 100]), tensor(191, device='cuda:0')],\n",
       " [torch.Size([64, 239, 100]), tensor(239, device='cuda:0')],\n",
       " [torch.Size([64, 74, 100]), tensor(74, device='cuda:0')],\n",
       " [torch.Size([64, 164, 100]), tensor(164, device='cuda:0')],\n",
       " [torch.Size([64, 145, 100]), tensor(145, device='cuda:0')],\n",
       " [torch.Size([64, 123, 100]), tensor(123, device='cuda:0')],\n",
       " [torch.Size([64, 42, 100]), tensor(42, device='cuda:0')],\n",
       " [torch.Size([64, 115, 100]), tensor(115, device='cuda:0')],\n",
       " [torch.Size([64, 126, 100]), tensor(126, device='cuda:0')],\n",
       " [torch.Size([64, 137, 100]), tensor(137, device='cuda:0')],\n",
       " [torch.Size([64, 403, 100]), tensor(403, device='cuda:0')],\n",
       " [torch.Size([64, 96, 100]), tensor(96, device='cuda:0')],\n",
       " [torch.Size([64, 799, 100]), tensor(799, device='cuda:0')],\n",
       " [torch.Size([64, 63, 100]), tensor(63, device='cuda:0')],\n",
       " [torch.Size([64, 162, 100]), tensor(162, device='cuda:0')],\n",
       " [torch.Size([64, 113, 100]), tensor(113, device='cuda:0')],\n",
       " [torch.Size([64, 129, 100]), tensor(129, device='cuda:0')],\n",
       " [torch.Size([64, 104, 100]), tensor(104, device='cuda:0')],\n",
       " [torch.Size([64, 121, 100]), tensor(121, device='cuda:0')],\n",
       " [torch.Size([64, 199, 100]), tensor(199, device='cuda:0')],\n",
       " [torch.Size([64, 321, 100]), tensor(321, device='cuda:0')],\n",
       " [torch.Size([64, 341, 100]), tensor(341, device='cuda:0')],\n",
       " [torch.Size([64, 226, 100]), tensor(226, device='cuda:0')],\n",
       " [torch.Size([64, 149, 100]), tensor(149, device='cuda:0')],\n",
       " [torch.Size([64, 432, 100]), tensor(432, device='cuda:0')],\n",
       " [torch.Size([64, 255, 100]), tensor(255, device='cuda:0')],\n",
       " [torch.Size([64, 220, 100]), tensor(220, device='cuda:0')],\n",
       " [torch.Size([64, 139, 100]), tensor(139, device='cuda:0')],\n",
       " [torch.Size([64, 178, 100]), tensor(178, device='cuda:0')],\n",
       " [torch.Size([64, 230, 100]), tensor(230, device='cuda:0')],\n",
       " [torch.Size([64, 157, 100]), tensor(157, device='cuda:0')],\n",
       " [torch.Size([64, 118, 100]), tensor(118, device='cuda:0')],\n",
       " [torch.Size([64, 69, 100]), tensor(69, device='cuda:0')],\n",
       " [torch.Size([64, 414, 100]), tensor(414, device='cuda:0')],\n",
       " [torch.Size([64, 142, 100]), tensor(142, device='cuda:0')],\n",
       " [torch.Size([64, 101, 100]), tensor(101, device='cuda:0')],\n",
       " [torch.Size([64, 151, 100]), tensor(151, device='cuda:0')],\n",
       " [torch.Size([64, 606, 100]), tensor(606, device='cuda:0')],\n",
       " [torch.Size([64, 124, 100]), tensor(124, device='cuda:0')],\n",
       " [torch.Size([64, 185, 100]), tensor(185, device='cuda:0')],\n",
       " [torch.Size([64, 79, 100]), tensor(79, device='cuda:0')],\n",
       " [torch.Size([64, 134, 100]), tensor(134, device='cuda:0')],\n",
       " [torch.Size([64, 279, 100]), tensor(279, device='cuda:0')],\n",
       " [torch.Size([64, 1601, 100]), tensor(1601, device='cuda:0')],\n",
       " [torch.Size([64, 313, 100]), tensor(313, device='cuda:0')],\n",
       " [torch.Size([64, 647, 100]), tensor(647, device='cuda:0')],\n",
       " [torch.Size([64, 305, 100]), tensor(305, device='cuda:0')],\n",
       " [torch.Size([64, 182, 100]), tensor(182, device='cuda:0')],\n",
       " [torch.Size([64, 147, 100]), tensor(147, device='cuda:0')],\n",
       " [torch.Size([64, 266, 100]), tensor(266, device='cuda:0')],\n",
       " [torch.Size([64, 705, 100]), tensor(705, device='cuda:0')],\n",
       " [torch.Size([64, 53, 100]), tensor(53, device='cuda:0')],\n",
       " [torch.Size([64, 111, 100]), tensor(111, device='cuda:0')],\n",
       " [torch.Size([64, 288, 100]), tensor(288, device='cuda:0')],\n",
       " [torch.Size([64, 450, 100]), tensor(450, device='cuda:0')],\n",
       " [torch.Size([64, 167, 100]), tensor(167, device='cuda:0')],\n",
       " [torch.Size([64, 195, 100]), tensor(195, device='cuda:0')],\n",
       " [torch.Size([64, 213, 100]), tensor(213, device='cuda:0')],\n",
       " [torch.Size([64, 918, 100]), tensor(918, device='cuda:0')],\n",
       " [torch.Size([64, 272, 100]), tensor(272, device='cuda:0')],\n",
       " [torch.Size([64, 107, 100]), tensor(107, device='cuda:0')],\n",
       " [torch.Size([64, 252, 100]), tensor(252, device='cuda:0')],\n",
       " [torch.Size([64, 310, 100]), tensor(310, device='cuda:0')],\n",
       " [torch.Size([64, 214, 100]), tensor(214, device='cuda:0')],\n",
       " [torch.Size([64, 272, 100]), tensor(272, device='cuda:0')],\n",
       " [torch.Size([64, 188, 100]), tensor(188, device='cuda:0')],\n",
       " [torch.Size([64, 318, 100]), tensor(318, device='cuda:0')],\n",
       " [torch.Size([64, 223, 100]), tensor(223, device='cuda:0')],\n",
       " [torch.Size([64, 144, 100]), tensor(144, device='cuda:0')],\n",
       " [torch.Size([64, 118, 100]), tensor(118, device='cuda:0')],\n",
       " [torch.Size([64, 153, 100]), tensor(153, device='cuda:0')],\n",
       " [torch.Size([64, 525, 100]), tensor(525, device='cuda:0')],\n",
       " [torch.Size([64, 166, 100]), tensor(166, device='cuda:0')],\n",
       " [torch.Size([64, 358, 100]), tensor(358, device='cuda:0')],\n",
       " [torch.Size([64, 162, 100]), tensor(162, device='cuda:0')],\n",
       " [torch.Size([64, 339, 100]), tensor(339, device='cuda:0')],\n",
       " [torch.Size([64, 112, 100]), tensor(112, device='cuda:0')],\n",
       " [torch.Size([64, 81, 100]), tensor(81, device='cuda:0')],\n",
       " [torch.Size([64, 439, 100]), tensor(439, device='cuda:0')],\n",
       " [torch.Size([64, 194, 100]), tensor(194, device='cuda:0')],\n",
       " [torch.Size([64, 133, 100]), tensor(133, device='cuda:0')],\n",
       " [torch.Size([64, 71, 100]), tensor(71, device='cuda:0')],\n",
       " [torch.Size([64, 117, 100]), tensor(117, device='cuda:0')],\n",
       " [torch.Size([64, 302, 100]), tensor(302, device='cuda:0')],\n",
       " [torch.Size([64, 396, 100]), tensor(396, device='cuda:0')],\n",
       " [torch.Size([64, 151, 100]), tensor(151, device='cuda:0')],\n",
       " [torch.Size([64, 349, 100]), tensor(349, device='cuda:0')],\n",
       " [torch.Size([64, 179, 100]), tensor(179, device='cuda:0')],\n",
       " [torch.Size([64, 110, 100]), tensor(110, device='cuda:0')],\n",
       " [torch.Size([64, 496, 100]), tensor(496, device='cuda:0')],\n",
       " [torch.Size([64, 173, 100]), tensor(173, device='cuda:0')],\n",
       " [torch.Size([64, 86, 100]), tensor(86, device='cuda:0')],\n",
       " [torch.Size([64, 789, 100]), tensor(789, device='cuda:0')],\n",
       " [torch.Size([64, 2470, 100]), tensor(2470, device='cuda:0')],\n",
       " [torch.Size([64, 127, 100]), tensor(127, device='cuda:0')],\n",
       " [torch.Size([64, 142, 100]), tensor(142, device='cuda:0')],\n",
       " [torch.Size([64, 198, 100]), tensor(198, device='cuda:0')],\n",
       " [torch.Size([64, 120, 100]), tensor(120, device='cuda:0')],\n",
       " [torch.Size([64, 128, 100]), tensor(128, device='cuda:0')],\n",
       " [torch.Size([64, 210, 100]), tensor(210, device='cuda:0')],\n",
       " [torch.Size([64, 76, 100]), tensor(76, device='cuda:0')],\n",
       " [torch.Size([64, 54, 100]), tensor(54, device='cuda:0')],\n",
       " [torch.Size([64, 164, 100]), tensor(164, device='cuda:0')],\n",
       " [torch.Size([64, 657, 100]), tensor(657, device='cuda:0')],\n",
       " [torch.Size([64, 103, 100]), tensor(103, device='cuda:0')],\n",
       " [torch.Size([64, 294, 100]), tensor(294, device='cuda:0')],\n",
       " [torch.Size([64, 100, 100]), tensor(100, device='cuda:0')],\n",
       " [torch.Size([64, 64, 100]), tensor(64, device='cuda:0')],\n",
       " [torch.Size([64, 558, 100]), tensor(558, device='cuda:0')],\n",
       " [torch.Size([64, 140, 100]), tensor(140, device='cuda:0')],\n",
       " [torch.Size([64, 287, 100]), tensor(287, device='cuda:0')],\n",
       " [torch.Size([64, 181, 100]), tensor(181, device='cuda:0')],\n",
       " [torch.Size([64, 139, 100]), tensor(139, device='cuda:0')],\n",
       " [torch.Size([64, 185, 100]), tensor(185, device='cuda:0')],\n",
       " [torch.Size([64, 130, 100]), tensor(130, device='cuda:0')],\n",
       " [torch.Size([64, 146, 100]), tensor(146, device='cuda:0')],\n",
       " [torch.Size([64, 381, 100]), tensor(381, device='cuda:0')],\n",
       " [torch.Size([64, 237, 100]), tensor(237, device='cuda:0')],\n",
       " [torch.Size([64, 157, 100]), tensor(157, device='cuda:0')],\n",
       " [torch.Size([64, 131, 100]), tensor(131, device='cuda:0')],\n",
       " [torch.Size([64, 279, 100]), tensor(279, device='cuda:0')],\n",
       " [torch.Size([64, 91, 100]), tensor(91, device='cuda:0')],\n",
       " [torch.Size([64, 124, 100]), tensor(124, device='cuda:0')],\n",
       " [torch.Size([64, 368, 100]), tensor(368, device='cuda:0')],\n",
       " [torch.Size([64, 148, 100]), tensor(148, device='cuda:0')],\n",
       " [torch.Size([64, 409, 100]), tensor(409, device='cuda:0')],\n",
       " [torch.Size([64, 136, 100]), tensor(136, device='cuda:0')],\n",
       " [torch.Size([64, 150, 100]), tensor(150, device='cuda:0')],\n",
       " [torch.Size([64, 43, 100]), tensor(43, device='cuda:0')],\n",
       " [torch.Size([64, 59, 100]), tensor(59, device='cuda:0')],\n",
       " [torch.Size([64, 176, 100]), tensor(176, device='cuda:0')],\n",
       " [torch.Size([64, 121, 100]), tensor(121, device='cuda:0')],\n",
       " [torch.Size([64, 475, 100]), tensor(475, device='cuda:0')],\n",
       " [torch.Size([64, 206, 100]), tensor(206, device='cuda:0')],\n",
       " [torch.Size([64, 170, 100]), tensor(170, device='cuda:0')],\n",
       " [torch.Size([64, 265, 100]), tensor(265, device='cuda:0')],\n",
       " [torch.Size([64, 248, 100]), tensor(248, device='cuda:0')],\n",
       " [torch.Size([64, 218, 100]), tensor(218, device='cuda:0')],\n",
       " [torch.Size([64, 49, 100]), tensor(49, device='cuda:0')],\n",
       " [torch.Size([64, 96, 100]), tensor(96, device='cuda:0')],\n",
       " [torch.Size([64, 134, 100]), tensor(134, device='cuda:0')],\n",
       " [torch.Size([64, 228, 100]), tensor(228, device='cuda:0')],\n",
       " [torch.Size([64, 258, 100]), tensor(258, device='cuda:0')],\n",
       " [torch.Size([64, 159, 100]), tensor(159, device='cuda:0')],\n",
       " [torch.Size([64, 137, 100]), tensor(137, device='cuda:0')],\n",
       " [torch.Size([64, 899, 100]), tensor(899, device='cuda:0')],\n",
       " [torch.Size([64, 456, 100]), tensor(456, device='cuda:0')],\n",
       " [torch.Size([64, 243, 100]), tensor(243, device='cuda:0')],\n",
       " [torch.Size([64, 168, 100]), tensor(168, device='cuda:0')],\n",
       " [torch.Size([64, 123, 100]), tensor(123, device='cuda:0')],\n",
       " [torch.Size([64, 155, 100]), tensor(155, device='cuda:0')],\n",
       " [torch.Size([64, 191, 100]), tensor(191, device='cuda:0')],\n",
       " [torch.Size([64, 201, 100]), tensor(201, device='cuda:0')],\n",
       " [torch.Size([64, 232, 100]), tensor(232, device='cuda:0')],\n",
       " [torch.Size([64, 598, 100]), tensor(598, device='cuda:0')],\n",
       " [torch.Size([64, 327, 100]), tensor(327, device='cuda:0')],\n",
       " [torch.Size([64, 115, 100]), tensor(115, device='cuda:0')],\n",
       " [torch.Size([64, 424, 100]), tensor(424, device='cuda:0')],\n",
       " [torch.Size([64, 126, 100]), tensor(126, device='cuda:0')],\n",
       " [torch.Size([64, 712, 100]), tensor(712, device='cuda:0')],\n",
       " [torch.Size([64, 143, 100]), tensor(143, device='cuda:0')],\n",
       " [torch.Size([40, 1376, 100]), tensor(1376, device='cuda:0')],\n",
       " [torch.Size([64, 580, 100]), tensor(580, device='cuda:0')],\n",
       " [torch.Size([64, 635, 100]), tensor(635, device='cuda:0')],\n",
       " [torch.Size([64, 256, 100]), tensor(256, device='cuda:0')],\n",
       " [torch.Size([64, 119, 100]), tensor(119, device='cuda:0')],\n",
       " [torch.Size([64, 176, 100]), tensor(176, device='cuda:0')],\n",
       " [torch.Size([64, 216, 100]), tensor(216, device='cuda:0')],\n",
       " [torch.Size([64, 89, 100]), tensor(89, device='cuda:0')],\n",
       " [torch.Size([64, 131, 100]), tensor(131, device='cuda:0')],\n",
       " [torch.Size([64, 309, 100]), tensor(309, device='cuda:0')],\n",
       " [torch.Size([64, 149, 100]), tensor(149, device='cuda:0')],\n",
       " [torch.Size([64, 124, 100]), tensor(124, device='cuda:0')],\n",
       " [torch.Size([64, 362, 100]), tensor(362, device='cuda:0')],\n",
       " [torch.Size([64, 66, 100]), tensor(66, device='cuda:0')],\n",
       " [torch.Size([64, 136, 100]), tensor(136, device='cuda:0')],\n",
       " [torch.Size([64, 121, 100]), tensor(121, device='cuda:0')],\n",
       " [torch.Size([64, 166, 100]), tensor(166, device='cuda:0')],\n",
       " [torch.Size([64, 237, 100]), tensor(237, device='cuda:0')],\n",
       " [torch.Size([64, 127, 100]), tensor(127, device='cuda:0')],\n",
       " [torch.Size([64, 147, 100]), tensor(147, device='cuda:0')],\n",
       " [torch.Size([64, 188, 100]), tensor(188, device='cuda:0')],\n",
       " [torch.Size([64, 302, 100]), tensor(302, device='cuda:0')],\n",
       " [torch.Size([64, 284, 100]), tensor(284, device='cuda:0')],\n",
       " [torch.Size([64, 211, 100]), tensor(211, device='cuda:0')],\n",
       " [torch.Size([64, 293, 100]), tensor(293, device='cuda:0')],\n",
       " [torch.Size([64, 168, 100]), tensor(168, device='cuda:0')],\n",
       " [torch.Size([64, 134, 100]), tensor(134, device='cuda:0')],\n",
       " [torch.Size([64, 243, 100]), tensor(243, device='cuda:0')],\n",
       " [torch.Size([64, 79, 100]), tensor(79, device='cuda:0')],\n",
       " [torch.Size([64, 338, 100]), tensor(338, device='cuda:0')],\n",
       " [torch.Size([64, 109, 100]), tensor(109, device='cuda:0')],\n",
       " [torch.Size([64, 199, 100]), tensor(199, device='cuda:0')],\n",
       " [torch.Size([64, 163, 100]), tensor(163, device='cuda:0')],\n",
       " [torch.Size([64, 225, 100]), tensor(225, device='cuda:0')],\n",
       " [torch.Size([64, 123, 100]), tensor(123, device='cuda:0')],\n",
       " [torch.Size([64, 60, 100]), tensor(60, device='cuda:0')],\n",
       " [torch.Size([64, 947, 100]), tensor(947, device='cuda:0')],\n",
       " [torch.Size([64, 801, 100]), tensor(801, device='cuda:0')],\n",
       " [torch.Size([64, 513, 100]), tensor(513, device='cuda:0')],\n",
       " [torch.Size([64, 349, 100]), tensor(349, device='cuda:0')],\n",
       " [torch.Size([64, 385, 100]), tensor(385, device='cuda:0')],\n",
       " [torch.Size([64, 153, 100]), tensor(153, device='cuda:0')],\n",
       " [torch.Size([64, 117, 100]), tensor(117, device='cuda:0')],\n",
       " [torch.Size([64, 138, 100]), tensor(138, device='cuda:0')],\n",
       " [torch.Size([64, 173, 100]), tensor(173, device='cuda:0')],\n",
       " [torch.Size([64, 264, 100]), tensor(264, device='cuda:0')],\n",
       " [torch.Size([64, 96, 100]), tensor(96, device='cuda:0')],\n",
       " [torch.Size([64, 155, 100]), tensor(155, device='cuda:0')],\n",
       " [torch.Size([64, 111, 100]), tensor(111, device='cuda:0')],\n",
       " [torch.Size([64, 142, 100]), tensor(142, device='cuda:0')],\n",
       " [torch.Size([64, 145, 100]), tensor(145, device='cuda:0')],\n",
       " [torch.Size([64, 126, 100]), tensor(126, device='cuda:0')],\n",
       " [torch.Size([64, 249, 100]), tensor(249, device='cuda:0')],\n",
       " [torch.Size([64, 72, 100]), tensor(72, device='cuda:0')],\n",
       " [torch.Size([64, 403, 100]), tensor(403, device='cuda:0')],\n",
       " [torch.Size([64, 220, 100]), tensor(220, device='cuda:0')],\n",
       " [torch.Size([64, 140, 100]), tensor(140, device='cuda:0')],\n",
       " [torch.Size([64, 106, 100]), tensor(106, device='cuda:0')],\n",
       " [torch.Size([64, 710, 100]), tensor(710, device='cuda:0')],\n",
       " [torch.Size([64, 113, 100]), tensor(113, device='cuda:0')],\n",
       " [torch.Size([64, 318, 100]), tensor(318, device='cuda:0')],\n",
       " [torch.Size([64, 132, 100]), tensor(132, device='cuda:0')],\n",
       " [torch.Size([64, 373, 100]), tensor(373, device='cuda:0')],\n",
       " [torch.Size([64, 207, 100]), tensor(207, device='cuda:0')],\n",
       " [torch.Size([64, 129, 100]), tensor(129, device='cuda:0')],\n",
       " [torch.Size([64, 55, 100]), tensor(55, device='cuda:0')],\n",
       " [torch.Size([64, 42, 100]), tensor(42, device='cuda:0')],\n",
       " [torch.Size([64, 179, 100]), tensor(179, device='cuda:0')],\n",
       " [torch.Size([64, 420, 100]), tensor(420, device='cuda:0')],\n",
       " [torch.Size([64, 192, 100]), tensor(192, device='cuda:0')],\n",
       " [torch.Size([64, 84, 100]), tensor(84, device='cuda:0')],\n",
       " [torch.Size([64, 231, 100]), tensor(231, device='cuda:0')],\n",
       " [torch.Size([64, 203, 100]), tensor(203, device='cuda:0')],\n",
       " [torch.Size([64, 541, 100]), tensor(541, device='cuda:0')],\n",
       " [torch.Size([64, 48, 100]), tensor(48, device='cuda:0')],\n",
       " [torch.Size([64, 101, 100]), tensor(101, device='cuda:0')],\n",
       " [torch.Size([64, 196, 100]), tensor(196, device='cuda:0')],\n",
       " [torch.Size([64, 182, 100]), tensor(182, device='cuda:0')],\n",
       " [torch.Size([64, 270, 100]), tensor(270, device='cuda:0')],\n",
       " [torch.Size([64, 151, 100]), tensor(151, device='cuda:0')],\n",
       " [torch.Size([64, 278, 100]), tensor(278, device='cuda:0')],\n",
       " [torch.Size([64, 170, 100]), tensor(170, device='cuda:0')],\n",
       " [torch.Size([64, 160, 100]), tensor(160, device='cuda:0')],\n",
       " [torch.Size([64, 485, 100]), tensor(485, device='cuda:0')],\n",
       " [torch.Size([64, 116, 100]), tensor(116, device='cuda:0')],\n",
       " [torch.Size([64, 438, 100]), tensor(438, device='cuda:0')],\n",
       " [torch.Size([64, 158, 100]), tensor(158, device='cuda:0')],\n",
       " [torch.Size([64, 464, 100]), tensor(464, device='cuda:0')],\n",
       " [torch.Size([64, 328, 100]), tensor(328, device='cuda:0')],\n",
       " [torch.Size([64, 185, 100]), tensor(185, device='cuda:0')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes = []\n",
    "for i, batch in enumerate(trainLoader, 0):\n",
    "                inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "                labels -= 1\n",
    "                o = lstm(inputs)\n",
    "                shapes.append([o[0].shape, max(length)])\n",
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 157, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 200])\n"
     ]
    }
   ],
   "source": [
    "print(o[1][0].permute(1,0,2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8f28cdba77a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 device), batch.label.type(torch.FloatTensor).to(device)\n\u001b[1;32m      5\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mo\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0mo\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm' is not defined"
     ]
    }
   ],
   "source": [
    "shapes = []\n",
    "for i, batch in enumerate(trainLoader, 0):\n",
    "                inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "                labels -= 1\n",
    "                o  = lstm(inputs)[1][0].permute(1,0,2)   \n",
    "                o  = conv(o)\n",
    "                o = pool(o)\n",
    "                o = dense(o.view(-1,24*51))\n",
    "                o = lstm2(o.view(-1,1,400))[1][0]\n",
    "                shapes.append(o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o  = lstm(inputs)[1][0].permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 24, 49])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 40, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256]),\n",
       " torch.Size([1, 64, 256])]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-cb499ffad8a9>, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-cb499ffad8a9>\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    x = self.dropout(x|)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Class for creating the neural network.\n",
    "class Network(tnn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.optimizer = None\n",
    "        self.criterion = None     \n",
    "\n",
    "        self.lstm1 = tnn.LSTM(50, 200, batch_first=True)\n",
    "        self.conv1 = tnn.Conv1d(1, 24, 5, padding=5)\n",
    "        self.relu = tnn.ReLU()\n",
    "        self.maxpool = tnn.MaxPool1d(4)\n",
    "        # TODO -> 先Dropout还是先normalize ？\n",
    "        self.dropout = tnn.Dropout()\n",
    "        \n",
    "        self.dense1 = tnn.Linear(24*51, 400)\n",
    "        self.norm1 = tnn.BatchNorm1d(400)\n",
    "        \n",
    "\n",
    "        # Relu\n",
    "        self.dense2 = tnn.Linear(400, 256)\n",
    "        # dropout\n",
    "        self.dense3 = tnn.Linear(256, 64)\n",
    "        # Relu\n",
    "        self.dense4 = tnn.Linear(64, 1)\n",
    "        \n",
    "        self.to(self.device)\n",
    "        print(self.device)    \n",
    "        \n",
    "        \n",
    "    def compile(self, optimizer, criterion):\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def fit(self, trainset, EPOCHS):\n",
    "        for epoch in range(EPOCHS):\n",
    "            running_loss = 0.0\n",
    "            for i, batch in enumerate(trainset, 0):\n",
    "                inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "                labels -= 1\n",
    "                self.optimizer.zero_grad()\n",
    "                #tnn.functional.batch_norm(inputs,0.5,0.5,training=True)\n",
    "                \n",
    "                predict = self(inputs.to(self.device),length)\n",
    "                loss = criterion(predict.view(-1), labels.to(self.device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                if i % 32 == 31:\n",
    "                    print(\"Epoch: %2d, Batch: %4d, Loss: %.3f\" % \n",
    "                              (epoch + 1, i + 1, running_loss / 32))\n",
    "                    running_loss = 0\n",
    "        print('trainning completed!')\n",
    "                \n",
    "        \n",
    "    def conv(self, features):\n",
    "        x = self.lstm1(features)[1][0].permute(1,0,2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "    \n",
    "        return x\n",
    "\n",
    "    def forward(self, input, length):\n",
    "        x = self.conv(input)\n",
    "        x = self.dense1(x.view(-1,24*51))\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense4(x)\n",
    "        \n",
    "        return tnn.functional.logsigmoid(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Network(\n",
      "  (lstm1): LSTM(50, 200, batch_first=True)\n",
      "  (conv1): Conv1d(1, 24, kernel_size=(5,), stride=(1,), padding=(5,))\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (dense1): Linear(in_features=1224, out_features=400, bias=True)\n",
      "  (norm1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dense2): Linear(in_features=400, out_features=256, bias=True)\n",
      "  (dense3): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (dense4): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Network()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = tnn.MSELoss()\n",
    "net.compile(optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1, Batch:   32, Loss: 0.553\n",
      "Epoch:  1, Batch:   64, Loss: 0.496\n",
      "Epoch:  1, Batch:   96, Loss: 0.495\n",
      "Epoch:  1, Batch:  128, Loss: 0.504\n",
      "Epoch:  1, Batch:  160, Loss: 0.482\n",
      "Epoch:  1, Batch:  192, Loss: 0.524\n",
      "Epoch:  1, Batch:  224, Loss: 0.507\n",
      "Epoch:  1, Batch:  256, Loss: 0.487\n",
      "Epoch:  1, Batch:  288, Loss: 0.500\n",
      "Epoch:  1, Batch:  320, Loss: 0.512\n",
      "Epoch:  1, Batch:  352, Loss: 0.490\n",
      "Epoch:  1, Batch:  384, Loss: 0.504\n",
      "Epoch:  2, Batch:   32, Loss: 0.479\n",
      "Epoch:  2, Batch:   64, Loss: 0.480\n",
      "Epoch:  2, Batch:   96, Loss: 0.506\n",
      "Epoch:  2, Batch:  128, Loss: 0.503\n",
      "Epoch:  2, Batch:  160, Loss: 0.473\n",
      "Epoch:  2, Batch:  192, Loss: 0.524\n",
      "Epoch:  2, Batch:  224, Loss: 0.509\n",
      "Epoch:  2, Batch:  256, Loss: 0.495\n",
      "Epoch:  2, Batch:  288, Loss: 0.529\n",
      "Epoch:  2, Batch:  320, Loss: 0.485\n",
      "Epoch:  2, Batch:  352, Loss: 0.494\n",
      "Epoch:  2, Batch:  384, Loss: 0.521\n",
      "Epoch:  3, Batch:   32, Loss: 0.500\n",
      "Epoch:  3, Batch:   64, Loss: 0.527\n",
      "Epoch:  3, Batch:   96, Loss: 0.498\n",
      "Epoch:  3, Batch:  128, Loss: 0.486\n",
      "Epoch:  3, Batch:  160, Loss: 0.499\n",
      "Epoch:  3, Batch:  192, Loss: 0.504\n",
      "Epoch:  3, Batch:  224, Loss: 0.495\n",
      "Epoch:  3, Batch:  256, Loss: 0.492\n",
      "Epoch:  3, Batch:  288, Loss: 0.504\n",
      "Epoch:  3, Batch:  320, Loss: 0.496\n",
      "Epoch:  3, Batch:  352, Loss: 0.499\n",
      "Epoch:  3, Batch:  384, Loss: 0.496\n",
      "trainning completed!\n"
     ]
    }
   ],
   "source": [
    "net.fit(trainLoader,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing():\n",
    "    def pre(x):\n",
    "        \"\"\"Called after tokenization\"\"\"\n",
    "        return x\n",
    "\n",
    "    def post(batch, vocab):\n",
    "        \"\"\"Called after numericalization but prior to vectorization\"\"\"\n",
    "        return batch, vocab\n",
    "\n",
    "    text_field = data.Field(lower=True, include_lengths=True, batch_first=True, preprocessing=pre, postprocessing=post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFunc():\n",
    "    \"\"\"\n",
    "    Define a loss function appropriate for the above networks that will\n",
    "    add a sigmoid to the output and calculate the binary cross-entropy.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Use a GPU if available, as it should be faster.\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \" + str(device))\n",
    "\n",
    "    # Load the training dataset, and create a data loader to generate a batch.\n",
    "    textField = PreProcessing.text_field\n",
    "    labelField = data.Field(sequential=False)\n",
    "\n",
    "    train, dev = IMDB.splits(textField, labelField, train=\"train\", validation=\"dev\")\n",
    "\n",
    "    textField.build_vocab(train, dev, vectors=GloVe(name=\"6B\", dim=50))\n",
    "    labelField.build_vocab(train, dev)\n",
    "\n",
    "    trainLoader, testLoader = data.BucketIterator.splits((train, dev), shuffle=True, batch_size=64,\n",
    "                                                         sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "\n",
    "    net = Network().to(device)\n",
    "    criterion =lossFunc()\n",
    "    optimiser = topti.Adam(net.parameters(), lr=0.001)  # Minimise the loss using the Adam algorithm.\n",
    "\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(trainLoader):\n",
    "            # Get a batch and potentially send it to GPU memory.\n",
    "            inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            labels -= 1\n",
    "\n",
    "            # PyTorch calculates gradients by accumulating contributions to them (useful for\n",
    "            # RNNs).  Hence we must manually set them to zero before calculating them.\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Forward pass through the network.\n",
    "            output = net(inputs, length)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # Calculate gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Minimise the loss according to the gradient.\n",
    "            optimiser.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 32 == 31:\n",
    "                print(\"Epoch: %2d, Batch: %4d, Loss: %.3f\" % (epoch + 1, i + 1, running_loss / 32))\n",
    "                running_loss = 0\n",
    "\n",
    "    num_correct = 0\n",
    "\n",
    "    # Save mode\n",
    "    torch.save(net.state_dict(), \"./model.pth\")\n",
    "    print(\"Saved model\")\n",
    "\n",
    "    # Evaluate network on the test dataset.  We aren't calculating gradients, so disable autograd to speed up\n",
    "    # computations and reduce memory usage.\n",
    "    with torch.no_grad():\n",
    "        for batch in testLoader:\n",
    "            # Get a batch and potentially send it to GPU memory.\n",
    "            inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            labels -= 1\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = torch.sigmoid(net(inputs, length))\n",
    "            predicted = torch.round(outputs)\n",
    "\n",
    "            num_correct += torch.sum(labels == predicted).item()\n",
    "\n",
    "    accuracy = 100 * num_correct / len(dev)\n",
    "\n",
    "    print(f\"Classification accuracy: {accuracy}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
