{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange\n",
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as topti\n",
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe\n",
    "from imdb_dataloader import IMDB\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "textField = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "labelField = data.Field(sequential=False)\n",
    "\n",
    "from imdb_dataloader import IMDB\n",
    "train, dev = IMDB.splits(textField, labelField, train=\"train\", validation=\"dev\")\n",
    "\n",
    "textField.build_vocab(train, dev, vectors=GloVe(name=\"6B\", dim=50))\n",
    "labelField.build_vocab(train, dev)\n",
    "\n",
    "trainLoader, testLoader = data.BucketIterator.splits((train, dev), shuffle=True, batch_size=64,\n",
    "                                                     sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = tnn.LSTM(50, 200, batch_first=True)\n",
    "\n",
    "conv = tnn.Conv1d(1, 24, 5, padding=5)\n",
    "pool = tnn.MaxPool1d(4)\n",
    "dense = tnn.Linear(200,400)\n",
    "lstm2 = tnn.LSTM(400, 256,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv1d(50, 50, 8, padding=5,).to(device)\n",
    "pool1 = torch.nn.MaxPool1d(4).to(device)\n",
    "conv2 = torch.nn.Conv1d(50, 50, 8, padding=5).to(device)\n",
    "pool2 = torch.nn.MaxPool1d(4).to(device) # shape (batch_size, channel)\n",
    "conv3 = torch.nn.Conv1d(50, 50, 8, padding=5).to(device)\n",
    "global_pool = torch.nn.functional.max_pool1d\n",
    "dense = torch.nn.Linear(1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "for i, batch in enumerate(trainLoader, 0):\n",
    "                inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "                labels -= 1\n",
    "                o = conv1(inputs.permute(0,2,1))\n",
    "                o = pool1(o)\n",
    "                o = conv2(o)\n",
    "                o = pool2(o)\n",
    "                o = conv3(o)\n",
    "                o = global_pool(o,kernel_size=o.shape[2])\n",
    "                shapes.append(o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([40, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1]),\n",
       " torch.Size([64, 50, 1])]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.ones(1,1,50).to(device)\n",
    "\n",
    "o = conv1(inputs.permute(0,2,1))\n",
    "o = pool1(o)\n",
    "o = conv2(o)\n",
    "o = pool2(o)\n",
    "o = conv3(o)\n",
    "o = torch.nn.functional.max_pool1d(o.permute(0,2,1),kernel_size=o.shape[1])\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(o[1][0].permute(1,0,2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "for i, batch in enumerate(trainLoader, 0):\n",
    "                inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "                labels -= 1\n",
    "                o  = lstm1(inputs)[1][0].permute(1,0,2)   \n",
    "                #o  = conv(o)\n",
    "                #o = pool(o)\n",
    "                o = dense(o.view(-1,200))\n",
    "                o = lstm2(o.view(-1,1,400))[1][0]\n",
    "                shapes.append(o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o  = lstm(inputs)[1][0].permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for creating the neural network.\n",
    "class Network(tnn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.optimizer = None\n",
    "        self.criterion = None     \n",
    "        \n",
    "        self.lstm1 = tnn.LSTM(50, 300, 1,batch_first=True)\n",
    "        self.relu = tnn.ReLU()\n",
    "        self.dropout = tnn.Dropout(0.3)\n",
    "        self.dense1 = tnn.Linear(300, 200)\n",
    "        self.dense2 = tnn.Linear(200, 128)\n",
    "        self.dense3 = tnn.Linear(128,64)\n",
    "        self.dense4 = tnn.Linear(64,1)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        self.to(self.device)\n",
    "        print(self.device) \n",
    "        \n",
    "    def forward(self, input, length):\n",
    "        x = self.lstm1(input)[1][0]\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense4(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def compile(self, optimizer, criterion):\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def fit(self, trainset, EPOCHS):\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            running_loss = 0.0\n",
    "            t_iter = tqdm(trainset)\n",
    "            for i, batch in (enumerate(t_iter, 0)):\n",
    "                inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "                labels -= 1\n",
    "                \n",
    "                predict = self(inputs.to(self.device),length)\n",
    "                loss = criterion(predict.view(-1), labels.to(self.device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                if i % 32 == 31:\n",
    "                    t_iter.set_postfix_str(\"Loss: %.3f\" %(running_loss / 32))\n",
    "                running_loss = 0\n",
    "        print('trainning completed!')\n",
    "        \n",
    "    def save(self, PATH='.model.pth'):\n",
    "        torch.save(self.state_dict(), PATH)\n",
    "        print('file saved!')\n",
    "        \n",
    "    def evaluate(self, testset):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(testset, 0):\n",
    "                inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "                labels -= 1\n",
    "                outputs = self(inputs.to(device),length).view(-1)\n",
    "                predicted = (outputs >= 0.5).to(int) # 用来把simoid后的结果变成非0即1\n",
    "                total += labels.shape[0]\n",
    "                correct += (predicted == labels.to(device)).sum().item()\n",
    "                \n",
    "        \n",
    "        print(total)\n",
    "        print(correct)\n",
    "        print(f'Accuracy of the network on the {total} test samples: %d %%' % (\n",
    "            100 * correct / total))\n",
    "                \n",
    "            \n",
    "    def predict(self, batch):\n",
    "        inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "        labels -= 1\n",
    "        with torch.no_grad():\n",
    "            outputs = self(inputs.to(device),length)\n",
    "            predicted = (outputs >= 0.5).to(int)\n",
    "        print('Predition --> \\t  ',predicted)\n",
    "        print('Ground Trueth --> ',labels.to(self.device))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Network(\n",
      "  (lstm1): LSTM(50, 300, batch_first=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (dense1): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (dense2): Linear(in_features=200, out_features=128, bias=True)\n",
      "  (dense3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (dense4): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Network()\n",
    "print(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = tnn.BCEWithLogitsLoss()\n",
    "net.compile(optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb3f7dca2b749dcadada2ba8e10833b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-6dfd1316489c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-9d13bb7a6a91>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, trainset, EPOCHS)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mt_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n\u001b[0m\u001b[1;32m     50\u001b[0m                 device), batch.label.type(torch.FloatTensor).to(device)\n\u001b[1;32m     51\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.fit(trainLoader,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6248\n",
      "3124\n",
      "Accuracy of the network on the 6248 test samples: 50 %\n"
     ]
    }
   ],
   "source": [
    "net.evaluate(testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing():\n",
    "    def pre(x):\n",
    "        \"\"\"Called after tokenization\"\"\"\n",
    "        return x\n",
    "\n",
    "    def post(batch, vocab):\n",
    "        \"\"\"Called after numericalization but prior to vectorization\"\"\"\n",
    "        return batch, vocab\n",
    "\n",
    "    text_field = data.Field(lower=True, include_lengths=True, batch_first=True, preprocessing=pre, postprocessing=post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFunc():\n",
    "    \"\"\"\n",
    "    Define a loss function appropriate for the above networks that will\n",
    "    add a sigmoid to the output and calculate the binary cross-entropy.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Use a GPU if available, as it should be faster.\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \" + str(device))\n",
    "\n",
    "    # Load the training dataset, and create a data loader to generate a batch.\n",
    "    textField = PreProcessing.text_field\n",
    "    labelField = data.Field(sequential=False)\n",
    "\n",
    "    train, dev = IMDB.splits(textField, labelField, train=\"train\", validation=\"dev\")\n",
    "\n",
    "    textField.build_vocab(train, dev, vectors=GloVe(name=\"6B\", dim=50))\n",
    "    labelField.build_vocab(train, dev)\n",
    "\n",
    "    trainLoader, testLoader = data.BucketIterator.splits((train, dev), shuffle=True, batch_size=64,\n",
    "                                                         sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "\n",
    "    net = Network().to(device)\n",
    "    criterion =lossFunc()\n",
    "    optimiser = topti.Adam(net.parameters(), lr=0.001)  # Minimise the loss using the Adam algorithm.\n",
    "\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(trainLoader):\n",
    "            # Get a batch and potentially send it to GPU memory.\n",
    "            inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            labels -= 1\n",
    "\n",
    "            # PyTorch calculates gradients by accumulating contributions to them (useful for\n",
    "            # RNNs).  Hence we must manually set them to zero before calculating them.\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Forward pass through the network.\n",
    "            output = net(inputs, length)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # Calculate gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Minimise the loss according to the gradient.\n",
    "            optimiser.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 32 == 31:\n",
    "                print(\"Epoch: %2d, Batch: %4d, Loss: %.3f\" % (epoch + 1, i + 1, running_loss / 32))\n",
    "                running_loss = 0\n",
    "\n",
    "    num_correct = 0\n",
    "\n",
    "    # Save mode\n",
    "    torch.save(net.state_dict(), \"./model.pth\")\n",
    "    print(\"Saved model\")\n",
    "\n",
    "    # Evaluate network on the test dataset.  We aren't calculating gradients, so disable autograd to speed up\n",
    "    # computations and reduce memory usage.\n",
    "    with torch.no_grad():\n",
    "        for batch in testLoader:\n",
    "            # Get a batch and potentially send it to GPU memory.\n",
    "            inputs, length, labels = textField.vocab.vectors[batch.text[0]].to(device), batch.text[1].to(\n",
    "                device), batch.label.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            labels -= 1\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = torch.sigmoid(net(inputs, length))\n",
    "            predicted = torch.round(outputs)\n",
    "\n",
    "            num_correct += torch.sum(labels == predicted).item()\n",
    "\n",
    "    accuracy = 100 * num_correct / len(dev)\n",
    "\n",
    "    print(f\"Classification accuracy: {accuracy}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
